{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1cc7a7",
   "metadata": {},
   "source": [
    "# 2.2 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefdc4b",
   "metadata": {},
   "source": [
    "1. In columns' names: no spaces and uppercase\n",
    "2. In columns data (type objec0t): no spaces and uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(<file_path_string>) - read csv files\n",
    "df.head() - take a look of the dataframe\n",
    "df.columns - retrieve colum names of a dataframe\n",
    "df.columns.str.lower() - lowercase all the letters\n",
    "df.columns.str.replace(' ', '_') - replace the space separator\n",
    "df.dtypes - retrieve data types of all features\n",
    "df.index - retrieve indices of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd5198",
   "metadata": {},
   "source": [
    "# 2.3 Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d8d62",
   "metadata": {},
   "source": [
    "To avoid long-tail distribution, we can use logarithmic values. If values are near 0, you should add \"1\" to all values, because log(0) does not exist. \n",
    "\n",
    "Long-tail distributions usually confuse the ML models, so the recommendation is \n",
    "to transform the target variable distribution to a normal one whenever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4055ed4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[col]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;66;03m#- returns a list of unique values in the series\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df[col]\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;66;03m#- returns the number of unique values in the series\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;66;03m#- retunrs the number of null values in the dataframe\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[col].unique() #- returns a list of unique values in the series\n",
    "df[col].nunique() #- returns the number of unique values in the series\n",
    "df.isnull().sum() #- retunrs the number of null values in the dataframe\n",
    "%matplotlib inline #- assure that plots are displayed in jupyter notebook's cells\n",
    "sns.histplot() #- show the histogram of a series\n",
    "np.log1p() #- applies log transformation to a variable and adds one to each result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c00b5",
   "metadata": {},
   "source": [
    "# 2.4 Setting up the validation framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62e5a6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2442898831.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    df.iloc[] #- returns subsets of records of a dataframe, being selected by numerical indices\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df.iloc[] #- returns subsets of records of a dataframe, being selected by numerical indices\n",
    "df.reset_index() #- restate the orginal indices\n",
    "del df[col] #- eliminates target variable\n",
    "\n",
    "np.arange() #- returns an array of numbers\n",
    "np.random.shuffle(10) #- returns a shuffled array\n",
    "np.random.seed() #- set a seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab138",
   "metadata": {},
   "source": [
    "### Steps: \n",
    "1. make a shuffled list `np.random.shuffle(idx)` and `df_shuffled = df.iloc[idx]`\n",
    "2. assign `n_train, n_val, n_test` \n",
    "3. slice the dataset `df_train = df_shuffled.iloc[:n_train].copy()`\n",
    "4. create y columns `y_train_orig = df_train.msrp.values`\n",
    "5. make it logarithmic to avoid long-tail distribution `y_train = np.log1p(df_train.msrp.values)`\n",
    "6. IMPORTANT! delete y column from dataset `del df_train['msrp']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df146530",
   "metadata": {},
   "source": [
    "# 2.5 Linear regression\n",
    "\n",
    "Bias term ($w_0$), which refers to the predictions if there is no information.   \n",
    "\n",
    "$y_{i} = w_0 + \\sum_{j=1}^n{w_j x_{ij}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3881476",
   "metadata": {},
   "source": [
    "# 2.8 Baseline solution\n",
    "\n",
    "1. select numerical columns  \n",
    "2. prepare X: `fillna(0)` and add bias column $w_0 = (0, ..., 0)^T$ (`column_stack`) \n",
    "3. use approximate formula to find $w, w_0$  \n",
    "4. $y_{pred} = w_0 + \\sum ...$  \n",
    "5. compare y pred and train using `sns.histplot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87236d",
   "metadata": {},
   "source": [
    "# 2.9 RMSE - Root Mean Squared Error\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{m} \\sum_{i=1}^m{(y_{pred} - y_i)^2}}$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e52598",
   "metadata": {},
   "source": [
    "# 2.13 Regularization\n",
    "\n",
    "After we created new columns for categorial features, the prediction and RSME suddenly became very huge. Its because of 2 or more the same columns in feature matrix X. To avoid this, before inverting $X^TX$, add E (I) matrix, multiplied by a small number. It will make you sure that there are no two similar columns now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f591bd",
   "metadata": {},
   "source": [
    "# 2.14 Tuning the model  \n",
    "\n",
    "The tuning consisted of finding the best regularization value, using the validation partition of the dataset. After obtaining the best regularization value, the model was trained with this regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c34b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
