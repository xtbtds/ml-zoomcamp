{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Data preparation\n",
        "\n",
        "`df.head().T` - take a look of the transposed dataframe  \n",
        "`df.columns` - retrieve column names of a dataframe  \n",
        "`df.dtypes` - retrieve data types of all series   \n",
        "`df.index` - retrive indices of a dataframe  \n",
        "`pd.to_numeric()` - convert a series values to numerical values. The errors=`coerce` argument allows making the transformation despite some encountered errors.   \n",
        "`(df.x == \"yes\").astype(int)` - convert x series of yes-no values to numerical values.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FSsxRRYGDvWe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yY-KK-geEND9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Setting up a validation \n",
        "\n",
        "`train_test_split` - Scikit-Learn class for splitting datasets. Linux shell command for downloading data. The `random_state` argument set a random seed for reproducibility purposes.  \n",
        "`df.reset_index(drop=True)` - reset the indices of a dataframe and delete the previous ones.  \n",
        "`df.x.values` - extract the values from x series  \n",
        "`del df['x']` - delete x series from a dataframe"
      ],
      "metadata": {
        "id": "QBXjFwzcEPUI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9fe5zCjEi4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 EDA\n",
        "1. Check NaN values:   \n",
        "  `.isnull().sum()`  \n",
        "2. Count the number of each value in column churn:  \n",
        "  `.churn.value_counts()`  \n",
        "  `.churn.value_counts(normalize=True)`  \n",
        "3. Find numberical and categorical values:  \n",
        "  `.dtypes`  \n",
        "  `categorical = [], numerical = []`   \n",
        "  `df[categorical].nunique()`  "
      ],
      "metadata": {
        "id": "NptYMAX9EjdL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3reWqx-yF1pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Feature importance\n",
        "\n",
        "1. ***Difference between global and group*** churn: global - group  \n",
        "2. ***Risk ratio***: group / global   \n",
        "\n",
        "`df.groupby('gender).churn.mean()`   \n",
        "To get a dataframe instead:  \n",
        "`df.groupby('gender).churn.agg['mean', 'count']`  \n",
        "\n",
        "3. For each in `categorical` do the same thing: calculate diff, risk, mean and count.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pm-2K0fTF2mY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOZOOEiYJikm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Feature Importance: Mutual Information (categorical)\n",
        "\n",
        "*Intuition*: how much can we learn about churn observing other variables?  \n",
        "\n",
        "\\\\\n",
        "`mutual_info_score(x, y)` - Scikit-Learn class for calculating the mutual information between the x target variable and y feature.  \n",
        "`df[x].apply(y)` - apply a y function to the x series of the df dataframe.  \n",
        "`df.sort_values(ascending=False).to_frame(name='x')` - sort values in an ascending order and called the column as x.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Kh49UuSJjAc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Aedo-DIk5aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.7 Feature importance: Correlation (numerical)\n",
        "\n",
        "$-1 \\leq r \\leq 1$  \n",
        "`df[numerical].corrwith(df.churh)`  \n"
      ],
      "metadata": {
        "id": "2b53PtDjk53s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HyALbgKfmuOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.8 One-hot encoding (categorical)\n",
        "\n",
        "To check - Compressed Sparse Row format  \n",
        "```\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "dicts = df[[..., ...]].iloc[:10].to_dict(orient='records')\n",
        "dv = DictVectorizer()\n",
        "dv.fit(dicts)\n",
        "dv.transform(dicts)\n",
        "dv.get_feature_names()\n",
        "```\n",
        "If we give it numerical values, it just ignores it. So we can one-hot-encode all dataframe at the same time without extracting only categorical values:\n",
        "```\n",
        "train_dicts = df[numerical + categorical].to_dict(orient='records')\n",
        "dv = DictVectorizer()\n",
        "#***\n",
        "dv.fit(train_dicts)\n",
        "list(dv.transform(train_dicts[:5])[0])      #to see how it looks like\n",
        "dv.get_feature_names(train_dicts)\n",
        "#*** \n",
        "#instead of all these lines:\n",
        "X_train = dv.fit_transform(train_dicts)\n",
        "```\n"
      ],
      "metadata": {
        "id": "D58CwzPWmuxM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KsIEEoh8qyO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.9 Logistic regression\n",
        "***Linear models:***\n",
        "- Linear Regression: $$g(x_i) = w_0 + w^Tx_i \\in (-\\infty; +âˆž)$$\n",
        "- Logistic Regression (classification): $$g(x_i) = SIGMOID(w_0 + w^Tx_i) \\in (0; 1)$$\n",
        "Sigmoid:\n",
        "$$\\sigma(x) = \\frac{1}{1 + exp(-x)}$$  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nEL4TsrPqzGn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obDT2Nlxs3Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.10 Training logistic regression with Scikit-Learn\n",
        "\n",
        "\n",
        "`LogisticRegression().fit_transform(x)` - Scikit-Learn class for calculating the logistic regression model.  \n",
        "`LogisticRegression().coef_[0]` - returns the coeffcients or weights of the LR model  \n",
        "`LogisticRegression().intercept_[0]` - returns the bias or intercept of the LR model  \n",
        "`LogisticRegression().predict[x]` - make predictions on the x dataset  \n",
        "`LogisticRegression().predict_proba[x]` - make predictions on the x dataset, and returns two columns with their probabilities for the two categories - soft predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "v9rVcfU-s3WX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZvYDFplqxfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.11 Model Interpretation\n",
        "\n"
      ],
      "metadata": {
        "id": "mA8RrMZNq0mS"
      }
    }
  ]
}